# ä¿å­˜canvas+åœæ­¢ç»˜ç”»ï¼Ÿï¼Ÿï¼Ÿ
import numpy as np
import os
import cv2
from . import HandTrackingModule_letter as htm
import torch
from .duan_validation_2 import ConvNet2
from torchvision import transforms
from PIL import Image

def custom_blur_demo(image):
    """é”åŒ–"""
    kernel = np.array([[0, -1, 0], [-1, 5, -1], [0, -1, 0]], np.float32) 
    return cv2.filter2D(image, -1, kernel=kernel)

def blur_demo(image):
    """æ¨¡ç³Š"""
    return cv2.blur(image, (15, 1))

def get_one_center(img):
    """è®¡ç®—å›¾åƒè´¨å¿ƒ"""
    # ç¡®ä¿å›¾åƒæ˜¯ç°åº¦å›¾åƒ
    if len(img.shape) == 3:
        img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)
    
    ret, thresh = cv2.threshold(img, 127, 255, 0)
    M = cv2.moments(thresh)
    if M["m00"] != 0:
        cX = (M["m10"] / M["m00"])
        cY = (M["m01"] / M["m00"])
    else:
        cX, cY = 0, 0
    return cX, cY

def recognize_letter_from_image(image_path):
    """ä½¿ç”¨letter_rec.pyçš„è¯†åˆ«é€»è¾‘è¯†åˆ«å›¾ç‰‡ä¸­çš„å­—æ¯"""
    try:
        # åŠ è½½æ¨¡å‹
        from . import paths
        model = ConvNet2()
        model.load_state_dict(torch.load(str(paths.models_dir() / 'EMNIST2_5.18.pth'), map_location='cpu'))
        model.eval()
        
        # è¯»å–å›¾ç‰‡ (ä½¿ç”¨letter_rec.pyä¸­çš„é€»è¾‘)
        img = cv2.imread(image_path, 0)  # ç°åº¦å›¾
        if img is None:
            return None
            
        # æå–ç»˜ç”»åŒºåŸŸ (å’Œletter_rec.pyä¸€æ ·)
        img = img[0:400, 400:800] 
        
        # é”åŒ–å’Œæ¨¡ç³Š (letter_rec.pyçš„å¤„ç†)
        kernel = np.array([[0, -1, 0], [-1, 5, -1], [0, -1, 0]], np.float32)
        img = cv2.filter2D(img, -1, kernel=kernel)
        img = cv2.blur(img, (15, 1))
        
        # è°ƒæ•´å¤§å°åˆ°20x20 (ä½¿ç”¨INTER_LANCZOS4é¿å…PILé”™è¯¯)
        img = cv2.resize(img, (20, 20), interpolation=cv2.INTER_LANCZOS4)
        
        # è®¡ç®—è´¨å¿ƒå¹¶å±…ä¸­ (letter_rec.pyçš„é€»è¾‘)
        ret, thresh = cv2.threshold(img, 127, 255, 0)
        M = cv2.moments(thresh)
        if M["m00"] != 0:
            cx = (M["m10"] / M["m00"])
            cy = (M["m01"] / M["m00"])
            M = np.float32([[1,0,(10-cx)],[0,1,10-cy]])
            img = cv2.warpAffine(img, M, (20, 20))
        
        # æ·»åŠ è¾¹æ¡†åˆ°28x28
        img = cv2.copyMakeBorder(img, 4, 4, 4, 4, cv2.BORDER_CONSTANT, value=[0,0,0])
        
        # è½¬æ¢å’Œé¢„æµ‹ (letter_rec.pyçš„é€»è¾‘)
        transform = transforms.Compose([
            transforms.ToTensor(),
            transforms.Normalize((0.1307,), (0.3081,))
        ])
        
        img_tensor = transform(img).unsqueeze(0)
        output = model(img_tensor)
        label = torch.argmax(output)
        index = label.item()
        
        # å­—æ¯è½¬æ¢ (å’Œletter_rec.pyä¸€æ ·)
        letter=["A/a","B/b","C/c","D/d","E/e","F/f","G/g","H/h","I/i","J/j","K/k","L/l","M/m","N/n","O/o","P/p"
                ,"Q/q","R/r","S/s","T/t","U/u","V/v","W/w","X/x","Y/y","Z/z"]
        
        if index >= 1 and index <= 26:
            return letter[index-1]
        else:
            return None
        
    except Exception as e:
        print(f"å­—æ¯è¯†åˆ«é”™è¯¯: {e}")
        return None

def written_letter(ui=None):
    brushThickness = 50
    eraserThickness = 15

    #folderPath = "Paint"
    #myList = os.listdir(folderPath)
    #print(myList)
    #overlayList = []

    #for imPath in myList:
       # image = cv2.imread(f'{folderPath}/{imPath}')
       # overlayList.append(image)
    #print(len(overlayList))

    #header = overlayList[0]
    drawColor = (255, 255, 255)
    videoSourceIndex = 0
    # Use V4L2 backend for Linux instead of DSHOW (Windows-specific)
    cap = cv2.VideoCapture(videoSourceIndex, cv2.CAP_V4L2)
    #cap = cv2.VideoCapture(0)
    
    # Check if camera opened successfully
    if not cap.isOpened():
        print(f"é”™è¯¯: æ— æ³•æ‰“å¼€æ‘„åƒå¤´ç´¢å¼• {videoSourceIndex}")
        return
    
    cap.set(3, 1280)#é•¿
    cap.set(4, 720)#å®½

    detector = htm.handDetector()
    xp, yp = 0, 0
    imgCanvas = np.zeros((720, 1280, 3), np.uint8)
    
    # è¯†åˆ«ç›¸å…³å˜é‡
    prediction_text = ""
    frame_count = 0
    last_prediction = None
    
    # åˆå§‹åŒ–è¾“å‡ºæ–‡ä»¶
    try:
        with open('test_letter.txt', 'w') as f:
            f.write("æ‰‹å†™å­—æ¯è¯†åˆ«ç»“æœ:\n")
        print("âœ… test_letter.txtæ–‡ä»¶åˆå§‹åŒ–æˆåŠŸ")
    except Exception as e:
        print(f"âŒ test_letter.txtæ–‡ä»¶åˆå§‹åŒ–å¤±è´¥: {e}")




    while cap.isOpened():
        #import image
        success, img = cap.read()
        
        # Check if frame was read successfully
        if not success:
            print("é”™è¯¯: æ— æ³•è¯»å–æ‘„åƒå¤´å¸§")
            break

        # find hand landmarks
        img = cv2.flip(img, 1)#æ°´å¹³ç¿»è½¬ï¼Œä¾¿äºä¹¦å†™
        img = detector.findHands(img)#æ‰¾ä¸€å¸§æ‰‹
        lmList = detector.findPosition(img, draw=False)#æ‰¾æ‰‹çš„åæ ‡
        a1,b1,c1,d1=400,0,400,400
        cv2.rectangle(img,(a1,b1),(a1+c1,b1+d1),(0,255,0),0)
        if len(lmList) != 0:
            #print(lmList)

            # tip of index and middle finger
            x1, y1 = lmList[8][1:]
            x2, y2 = lmList[12][1:]

            # check which fingures are up
            fingers = detector.fingersUp()
            # print(fingers)

            # if selection mode - two fingers are up
            #if fingers[1] and fingers[2]:
             #   xp, yp = 0, 0
              #  print("Selection Mode")
               # if y1 < 125:
                    # checking for click
                #    if 250<x1<450:
                 #       header = overlayList[0]
                  #      drawColor = (255, 0, 255)
                   # elif 550<x1<750:
                    #    header = overlayList[1]
                     #   drawColor = (255, 0, 100)
                    #elif 800<x1<950:
                     #   header = overlayList[2]
                      #  drawColor = (0, 255, 0)
                    #elif 1050<x1<1200:
                     #   header = overlayList[3]
                      #  drawColor = (0, 0, 0)

               # cv2.rectangle(img, (x1, y1 - 25), (x2, y2 + 25), drawColor, cv2.FILLED)
               
            # if drawing mode - index finger is up
            if  fingers[1] and fingers[2] == False:
                
                cv2.circle(img, (x1,y1), 15, drawColor, cv2.FILLED)#åœ¨æ¯ä¸€ç‚¹ç”»åœ†åœˆ
                
                print("Drawing Mode")

                if xp == 0 and yp == 0:#å®ç°ä¸ä»åŸç‚¹è·Ÿéš
                    xp, yp = x1, y1

                # if drawColor == (255, 0, 255):
                #     cv2.line(img, (xp, yp), (x1, y1), drawColor, brushThickness)
                #     cv2.line(imgCanvas, (xp, yp), (x1, y1), drawColor, brushThickness)
                # else:
                cv2.line(img, (xp, yp), (x1, y1), drawColor, brushThickness)#å½“å‰ç‚¹å’Œä¹‹å‰ç‚¹ä¹‹é—´è¿çº¿
                cv2.line(imgCanvas, (xp, yp), (x1, y1), drawColor, brushThickness)
            #cv2.rectangle(img,(xp,yp),(xp+500,yp+500),(255,255,255),3)
            xp, yp = x1, y1#ä¸æ–­æ›´æ–°å®ç°ä¸¤ç‚¹ä¸æ–­è¿çº¿
                    

                
        
        # imgGray = cv2.cvtColor(imgCanvas, cv2.COLOR_BGR2GRAY)#ç°åº¦åŒ–
        # _, imgInv = cv2.threshold(imgGray, 50, 255, cv2.THRESH_BINARY_INV)#äºŒå€¼åŒ–
        # imgInv = cv2.cvtColor(imgInv, cv2.COLOR_GRAY2BGR)#é»‘ç™½åŒ–
        # img = cv2.bitwise_and(img, imgInv)

        # å®æ—¶ä¿å­˜test_letter.jpgå¹¶è¯†åˆ«ï¼ˆæ¯10å¸§æ‰§è¡Œä¸€æ¬¡ï¼‰
        frame_count += 1
        if frame_count % 10 == 0:
            # ä¿å­˜Canvasåˆ°test_letter.jpg
            cv2.imwrite("./test_letter.jpg", imgCanvas)
            
            # æ£€æŸ¥ç”»å¸ƒæ˜¯å¦æœ‰å†…å®¹
            roi_debug = imgCanvas[0:400, 400:800]
            roi_sum = np.sum(roi_debug)
            
            if roi_sum > 0:  # ç”»å¸ƒæœ‰å†…å®¹æ—¶æ‰è¿›è¡Œè¯†åˆ«
                # ä½¿ç”¨letter_recçš„è¯†åˆ«é€»è¾‘è¯†åˆ«test_letter.jpg
                predicted_letter = recognize_letter_from_image("./test_letter.jpg")
                
                if predicted_letter is not None:
                    # å®æ—¶è¾“å‡ºåˆ°æ§åˆ¶å°ï¼ˆåƒæ•°å­—è¯†åˆ«é‚£æ ·åˆ·å±æ˜¾ç¤ºï¼‰
                    print(f"[{predicted_letter}]")
                    
                    prediction_text = f"{predicted_letter}"
                    
                    # **åƒletter_gesture.pyé‚£æ ·ï¼Œæ¯æ¬¡è¯†åˆ«æˆåŠŸéƒ½æ›´æ–°UI**
                    if ui is not None:
                        ui.textBrowser.append(str(predicted_letter))
                    
                    # ä¿å­˜åˆ°test_letter.txtæ–‡ä»¶ï¼ˆåƒæ•°å­—è¯†åˆ«é‚£æ ·ï¼‰
                    try:
                        with open('test_letter.txt', 'a') as f:
                            f.write(f"[{predicted_letter}]\n")
                    except Exception as e:
                        print(f"æ–‡ä»¶å†™å…¥é”™è¯¯: {e}")
                    
                    # å¦‚æœè¯†åˆ«ç»“æœå‘ç”Ÿå˜åŒ–ï¼Œè¾“å‡ºæ›´æ˜æ˜¾çš„æç¤º
                    if last_prediction != predicted_letter:
                        print(f"ğŸ”¥ è¯†åˆ«åˆ°æ–°å­—æ¯: {predicted_letter}")
                        last_prediction = predicted_letter
                else:
                    prediction_text = "è¯†åˆ«å¤±è´¥"
                    print("âš ï¸  ç”»å¸ƒæœ‰å†…å®¹ä½†è¯†åˆ«å¤±è´¥")
            else:
                prediction_text = ""
                if frame_count % 100 == 0:  # æ¯100å¸§æç¤ºä¸€æ¬¡
                    print("â„¹ï¸  ç”»å¸ƒåŒºåŸŸä¸ºç©º")

        img = cv2.bitwise_or(img, imgCanvas)#é€šè¿‡ä¸é»‘è‰²èƒŒæ™¯å›¾çš„æˆ–è¿ç®—ï¼Œå®ç°ç™½è‰²è½¨è¿¹åœ¨imgä¸Šçš„ä¿ç•™
        
        # åœ¨å›¾åƒä¸Šæ˜¾ç¤ºè¯†åˆ«ç»“æœï¼ˆåƒletter_gesture.pyé‚£æ ·çš„å¤§å­—ä½“é»„è‰²æ˜¾ç¤ºï¼‰
        if prediction_text and prediction_text != "è¯†åˆ«å¤±è´¥":
            # å¤§å­—ä½“æ˜¾ç¤ºå­—æ¯ï¼ˆåƒletter_gesture.pyé‚£æ ·ï¼‰
            cv2.putText(img, ' %s' % prediction_text, (90, 90), cv2.FONT_HERSHEY_SIMPLEX, 3, (255, 255, 0), 5, cv2.LINE_AA)
        elif prediction_text == "è¯†åˆ«å¤±è´¥":
            # è¯†åˆ«å¤±è´¥çš„æç¤º
            cv2.putText(img, "Fail", (90, 90), cv2.FONT_HERSHEY_SIMPLEX, 1.5, (0, 0, 255), 3)
        
        cv2.imshow("Canvas", imgCanvas)
        cv2.imshow("Image", img)
        cv2.imwrite("./test_letter.jpg", imgCanvas)
        key = cv2.waitKey(1) & 0xFF
        if key == ord('q'):  # æŒ‰qé€€å‡º
            break
        elif key == ord('c') or key == ord('C'):  # æ¸…ç©ºç”»å¸ƒ
            imgCanvas = np.zeros((720, 1280, 3), np.uint8)
            prediction_text = ""
            last_prediction = None
            print("ğŸ§¹ ç”»å¸ƒå·²æ¸…ç©ºï¼Œå‡†å¤‡è¯†åˆ«æ–°å­—æ¯")
            
            # æ¸…ç©ºtest_letter.jpg
            cv2.imwrite("./test_letter.jpg", imgCanvas)
            
            # åœ¨test_letter.txtä¸­è®°å½•æ¸…ç©ºæ“ä½œ
            try:
                with open('test_letter.txt', 'a') as f:
                    f.write("--- ç”»å¸ƒå·²æ¸…ç©º ---\n")
            except:
                pass
    
    cap.release()
    cv2.destroyAllWindows()

