# ä¿å­˜canvas+åœæ­¢ç»˜ç”»ï¼Ÿï¼Ÿï¼Ÿ
import numpy as np
import os
import cv2
from tracking import HandTrackingModule_letter as htm
import torch
from ml.duan_validation_2 import ConvNet2
from torchvision import transforms
from PIL import Image

def custom_blur_demo(image):
    """é”åŒ–"""
    kernel = np.array([[0, -1, 0], [-1, 5, -1], [0, -1, 0]], np.float32) 
    return cv2.filter2D(image, -1, kernel=kernel)

def blur_demo(image):
    """æ¨¡ç³Š"""
    return cv2.blur(image, (15, 1))

def get_one_center(img):
    """è®¡ç®—å›¾åƒè´¨å¿ƒ"""
    if len(img.shape) == 3:
        img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)
    ret, thresh = cv2.threshold(img, 127, 255, 0)
    M = cv2.moments(thresh)
    if M["m00"] != 0:
        cX = (M["m10"] / M["m00"]) ; cY = (M["m01"] / M["m00"])
    else:
        cX, cY = 0, 0
    return cX, cY

def recognize_letter_from_image(image_path):
    try:
        from utils import paths
        model_path = paths.models_dir() / 'EMNIST2_5.18.pth'
        if not model_path.exists():
            print(f"æœªæ‰¾åˆ°å­—æ¯æ¨¡å‹æƒé‡: {model_path}")
            return None
        model = ConvNet2()
        model.load_state_dict(torch.load(str(model_path), map_location='cpu'))
        model.eval()
        img = cv2.imread(image_path, 0)
        if img is None:
            return None
        img = img[0:400, 400:800]
        kernel = np.array([[0, -1, 0], [-1, 5, -1], [0, -1, 0]], np.float32)
        img = cv2.filter2D(img, -1, kernel=kernel)
        img = cv2.blur(img, (15, 1))
        img = cv2.resize(img, (20, 20), interpolation=cv2.INTER_LANCZOS4)
        ret, thresh = cv2.threshold(img, 127, 255, 0)
        M = cv2.moments(thresh)
        if M["m00"] != 0:
            cx = (M["m10"] / M["m00"]) ; cy = (M["m01"] / M["m00"])
            M = np.float32([[1,0,(10-cx)],[0,1,10-cy]])
            img = cv2.warpAffine(img, M, (20, 20))
        img = cv2.copyMakeBorder(img, 4, 4, 4, 4, cv2.BORDER_CONSTANT, value=[0,0,0])
        transform = transforms.Compose([
            transforms.ToTensor(),
            transforms.Normalize((0.1723,), (0.3309,))
        ])
        img_tensor = transform(img).unsqueeze(0)
        output = model(img_tensor)
        label = torch.argmax(output)
        index = label.item()
        letter=["A/a","B/b","C/c","D/d","E/e","F/f","G/g","H/h","I/i","J/j","K/k","L/l","M/m","N/n","O/o","P/p"
                ,"Q/q","R/r","S/s","T/t","U/u","V/v","W/w","X/x","Y/y","Z/z"]
        if 1 <= index <= 26:
            return letter[index-1]
        return None
    except Exception as e:
        print(f"å­—æ¯è¯†åˆ«é”™è¯¯: {e}")
        return None

def written_letter(ui=None):
    brushThickness = 50
    eraserThickness = 15
    drawColor = (255, 255, 255)
    videoSourceIndex = 0
    cap = cv2.VideoCapture(videoSourceIndex, cv2.CAP_V4L2)
    if not cap.isOpened():
        err = f"é”™è¯¯: æ— æ³•æ‰“å¼€æ‘„åƒå¤´ç´¢å¼• {videoSourceIndex}ã€‚å¯è¿è¡Œ scripts/detect_and_update_camera_index.py ä¿®å¤ã€‚"
        print(err)
        if ui is not None:
            try:
                ui.textBrowser.append(err)
            except Exception:
                pass
        return
    cap.set(3, 1280)
    cap.set(4, 720)
    detector = htm.handDetector()
    xp, yp = 0, 0
    imgCanvas = np.zeros((720, 1280, 3), np.uint8)
    prediction_text = ""
    frame_count = 0
    last_prediction = None
    try:
        with open('test_letter.txt', 'w') as f:
            f.write("æ‰‹å†™å­—æ¯è¯†åˆ«ç»“æœ:\n")
        print("âœ… test_letter.txtæ–‡ä»¶åˆå§‹åŒ–æˆåŠŸ")
    except Exception as e:
        print(f"âŒ test_letter.txtæ–‡ä»¶åˆå§‹åŒ–å¤±è´¥: {e}")

    while cap.isOpened():
        success, img = cap.read()
        if not success:
            print("é”™è¯¯: æ— æ³•è¯»å–æ‘„åƒå¤´å¸§")
            break
        img = cv2.flip(img, 1)
        img = detector.findHands(img)
        lmList = detector.findPosition(img, draw=False)
        a1,b1,c1,d1=400,0,400,400
        cv2.rectangle(img,(a1,b1),(a1+c1,b1+d1),(0,255,0),0)
        if len(lmList) != 0:
            x1, y1 = lmList[8][1:]
            x2, y2 = lmList[12][1:]
            fingers = detector.fingersUp()
            if fingers[1] and fingers[2] == False:
                cv2.circle(img, (x1,y1), 15, drawColor, cv2.FILLED)
                if xp == 0 and yp == 0:
                    xp, yp = x1, y1
                cv2.line(img, (xp, yp), (x1, y1), drawColor, brushThickness)
                cv2.line(imgCanvas, (xp, yp), (x1, y1), drawColor, brushThickness)
            xp, yp = x1, y1

        frame_count += 1
        if frame_count % 10 == 0:
            cv2.imwrite("./test_letter.jpg", imgCanvas)
            roi_debug = imgCanvas[0:400, 400:800]
            roi_sum = np.sum(roi_debug)
            if roi_sum > 0:
                predicted_letter = recognize_letter_from_image("./test_letter.jpg")
                if predicted_letter is not None:
                    print(f"[{predicted_letter}]")
                    prediction_text = f"{predicted_letter}"
                    if ui is not None:
                        ui.textBrowser.append(str(predicted_letter))
                    try:
                        with open('test_letter.txt', 'a') as f:
                            f.write(f"[{predicted_letter}]\n")
                    except Exception as e:
                        print(f"æ–‡ä»¶å†™å…¥é”™è¯¯: {e}")
                    if last_prediction != predicted_letter:
                        print(f"ğŸ”¥ è¯†åˆ«åˆ°æ–°å­—æ¯: {predicted_letter}")
                        last_prediction = predicted_letter
                else:
                    prediction_text = "è¯†åˆ«å¤±è´¥"
                    print("âš ï¸  ç”»å¸ƒæœ‰å†…å®¹ä½†è¯†åˆ«å¤±è´¥")
            else:
                prediction_text = ""
                if frame_count % 100 == 0:
                    print("â„¹ï¸  ç”»å¸ƒåŒºåŸŸä¸ºç©º")

        img = cv2.bitwise_or(img, imgCanvas)
        if prediction_text and prediction_text != "è¯†åˆ«å¤±è´¥":
            cv2.putText(img, ' %s' % prediction_text, (90, 90), cv2.FONT_HERSHEY_SIMPLEX, 3, (255, 255, 0), 5, cv2.LINE_AA)
        elif prediction_text == "è¯†åˆ«å¤±è´¥":
            cv2.putText(img, "Fail", (90, 90), cv2.FONT_HERSHEY_SIMPLEX, 1.5, (0, 0, 255), 3)

        cv2.imshow("Canvas", imgCanvas)
        cv2.imshow("Image", img)
        cv2.imwrite("./test_letter.jpg", imgCanvas)
        key = cv2.waitKey(1) & 0xFF
        if key == ord('q'):
            break
        elif key == ord('c') or key == ord('C'):
            imgCanvas = np.zeros((720, 1280, 3), np.uint8)
            prediction_text = ""
            last_prediction = None
            print("ğŸ§¹ ç”»å¸ƒå·²æ¸…ç©ºï¼Œå‡†å¤‡è¯†åˆ«æ–°å­—æ¯")
            cv2.imwrite("./test_letter.jpg", imgCanvas)
            try:
                with open('test_letter.txt', 'a') as f:
                    f.write("--- ç”»å¸ƒå·²æ¸…ç©º ---\n")
            except:
                pass
    cap.release()
    cv2.destroyAllWindows()
